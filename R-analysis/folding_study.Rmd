---
title: "Impact of folding acquisition"
author: "F. Suter"
date: "04/08/2014"
output: html_document
---

In this document, we analyze the impact of folded acquisition, i.e., executing with more than process per core, on the Time-Independent ScalaTrace traces, in terms of execution time and contents of the traces.

##Init
First load all the needed traces. The format of the 'time' dataframe is

  * Timer: Application (output of the benchmark), Real and User (as given by the time command)
  
  * Factor: how many processes were run on a single core. Factor=1 correspond to the "Regular" acquisition mode.
  
  * Time: the reported time
  
  * Regular: for each entry, we report the time of the Regular acquisition to ease the processing.
  
```{r}
library(ggplot2)
library(reshape2)                 #for melt
library(plyr)                     #for colwise
setwd('~/SVN/Anshul/ScalaTrace-TI')

# To analyze the impact on acquisition time
ti_times <- read.csv('datasets/ti_folding_times.csv',sep =',')
td_times <- read.csv('datasets/td_folding_times.csv',sep =',')

# To analyze the impact on stored numbers of instructions 
inst_regular <- read.csv('datasets/ti_folding_regular.csv', sep=',')
inst_2 <- read.csv('datasets/ti_folding_2.csv', sep=',')
inst_4 <- read.csv('datasets/ti_folding_4.csv', sep=',')
inst_8 <- read.csv('datasets/ti_folding_8.csv', sep=',')
inst_16 <- read.csv('datasets/ti_folding_16.csv', sep=',')
inst_32 <- read.csv('datasets/ti_folding_32.csv', sep=',')

# To analyze the impact on stored delta times
time_regular <- read.csv('datasets/td_folding_1.csv', sep=',')
time_2 <- read.csv('datasets/td_folding_2.csv', sep=',')
time_4 <- read.csv('datasets/td_folding_4.csv', sep=',')
time_8 <- read.csv('datasets/td_folding_8.csv', sep=',')
time_16 <- read.csv('datasets/td_folding_16.csv', sep=',')
time_32 <- read.csv('datasets/td_folding_32.csv', sep=',')
```

## Analysis of the impact of folding on the trace acquisition time

We first plot the execution time for each folding factor and each timer.

```{r}
ggplot(ti_times, aes(x=Factor, y=Time, color=Timer, shape=Timer)) +geom_line() + geom_point(size=3) + ylab("Execution Time (in seconds)") + xlab("Folding Factor") + scale_x_discrete(breaks=ti_times$Factor)
```

We can see that the execution time grows linearly with the folding factor. The time reported by the benchmark is close to what is returned by the time command, but seems to include the time spent in the system too (closer to real than to user).

We confirm the linear evolution by plotting the slowdown caused by the folded execution, that is the execution time for a given folding factor divided by the time for the "regular" acquisition. From now on, we focus on the "Application" timer:

```{r}
ggplot(ti_times[ti_times$Timer=="Application",], aes(x=Factor, y=Time/Regular, color=Timer, shape=Timer)) +geom_line() + geom_point(size=3) + ylab("Slowdown") + xlab("Folding Factor") + scale_x_discrete(breaks=ti_times$Factor) + scale_y_continuous(breaks=ti_times$Factor, labels=ti_times$Factor, limits=c(1,32))
```

The linearity is even more glaring when we look at the time of a folded acquisition divided by the time of the regular acquisition multiplied by the corresponding folding factor. The obtained values should be very close to 1.

```{r}
ggplot(ti_times[ti_times$Timer=="Application",], aes(x=Factor, y=Time/(Regular*Factor), color=Timer, shape=Timer)) +geom_line() + geom_point(size=3) + ylab("Ratio") + xlab("Folding Factor") + scale_x_discrete(breaks=ti_times$Factor) + geom_hline(yintercept=1) +ylim(0.90, 1.10)
```

We can conclude than we fold an acquisition, the time to obtain the trace is more or less multiplied by the chosen folding factor. 

We observe an interesting thing with the Timed traces. For each folding factor, we acquired traces using 1, 2, or the 4 cores of a node. 

```{r}
td_times$cores <- factor(td_times$cores)

ggplot(td_times, aes(x=Factor, y=Time, color=cores)) +geom_line() + geom_point(size=3) + ylab("Execution Time (in seconds)") + xlab("Folding Factor") + scale_x_discrete(breaks=td_times$Factor)

ggplot(td_times, aes(x=Factor, y=Time/(Regular), color=cores)) +geom_line() +geom_point(size=3)+ ylab("Slowdown") + xlab("Folding Factor") + scale_x_discrete(breaks=td_times$Factor) 
```

We see that using more than one core per node leads to worse acquisition times and slowdowns. This is likely to be caused by the OS scheduler that moves processes from one core to another and cause an overhead. Pining processes to cores might solves this issue. 

## Analysis of of the impact of folding on instruction counts

Now, we want to determine whether folding the execution modifies the average number of instructions stored for each event. This shouldn't be the case. To verify this assumptiom, we first build a dataframe that compute the ratio of the values stored for a folded execution to the regular mode. 

```{r}
inst_ratios = data.frame(inst_2$COMP.4c.avg/inst_regular$COMP.4c.avg, 
                         inst_4$COMP.4c.avg/inst_regular$COMP.4c.avg,
                         inst_8$COMP.4c.avg/inst_regular$COMP.4c.avg, 
                         inst_16$COMP.4c.avg/inst_regular$COMP.4c.avg, 
                         inst_32$COMP.4c.avg/inst_regular$COMP.4c.avg)

names(inst_ratios) <- c(2, 4,8,16,32)
```

We plot the distribution of these ratios as a boxplot.
```{r}
ggplot(melt(inst_ratios), aes(variable, value)) + geom_boxplot() + xlab("Folding factor") + ylab("(Folded/Regular) Instruction Ratio")
```

Unfortunately, an outlier flattens the boxplot. We have to look for this event: check the summary, find the minimum values for each column, and on which row(s) these values are:

```{r}
summary(inst_ratios)
colwise(min)(inst_ratios)
colwise(which.min)(inst_ratios)
```

All the minimum values are on the last line! look at the last line of 'inst_regular' and 'inst_2'.

```{r}
tail (inst_regular, n=1)
tail (inst_2, n=1)
```

A lot more instructions are executed in the MPI_Finalize function (opcode=1045) in the regular mode. By looking at the raw traces, we can see that:

  * For all the folded modes, the maximum number of instructions is around 600
  
  * In the regular mode, 63 processes (all but 1 then) report a large number of instructions
  
  * Interestingly, the last process in the regular one also report around 600 instructions
  
This difference might be related to the fact that the PAPI counter are stopped in the MPI_Finalize function. There might be bug there or something that requires some investigations. As it is not critical for the time being, we remove this last line and replot the boxplot.

```{r}
no_finalize=inst_ratios[-nrow(inst_ratios),]
ggplot(melt(no_finalize), aes(variable, value)) + geom_boxplot() + xlab("Folding factor") + ylab("(Folded/Regular) Instruction Ratio")
```

The box is very flat and centered on 1, with only a few outliers as confirmed by the summary

```{r}
summary(no_finalize)
```

We can conclude that folding the execution has **no impact** on the contents of the trace, *at the exception of the MPI_finalize event that requires a deeper investigation*

## Analysis of the impact of folding on delta times

Here, we conduct the same kind of analysis but on timed traces to determine the impact of folding on timers. As the processes have to compute for the CPU resource, the stored values should increase with the folding factor, thus preventing the usage of such traces for replay.

We first build a dataframe that compute the ratio of the values stored for a folded execution to the regular mode. 

```{r}
time_ratios = data.frame(time_2$COMP.4b.avg/time_regular$COMP.4b.avg, 
                         time_4$COMP.4b.avg/time_regular$COMP.4b.avg,                 
                         time_8$COMP.4b.avg/time_regular$COMP.4b.avg, 
                         time_16$COMP.4b.avg/time_regular$COMP.4b.avg, 
                         time_32$COMP.4b.avg/time_regular$COMP.4b.avg)

names(time_ratios) <- c(2,4,8,16,32)
```

Then we plot the distribution of these ratios as a boxplot.

```{r}
ggplot(melt(time_ratios), aes(variable, value)) + geom_boxplot() + xlab("Folding factor") + ylab("(Folded/Regular) Time Ratio") 
```
Outliers prevents to see anything. Replot without displaying them.

```{r}
ggplot(melt(time_ratios), aes(variable, value)) + geom_boxplot(outlier.shape = NA) + xlab("Folding factor") + ylab("(Folded/Regular) Time Ratio")+ylim(0,35)

summary(time_ratios)
```

We see an increase, but not as expected. However we see that the 3rd Quartile value roughly doubles with the folding factor. Look at the values instead of ratios..

```{r}
times = data.frame(time_regular$COMP.4b.avg, 
                    time_2$COMP.4b.avg,
                    time_4$COMP.4b.avg,               
                    time_8$COMP.4b.avg, 
                    time_16$COMP.4b.avg, 
                    time_32$COMP.4b.avg)
names(times) <- c(1,2,4,8,16,32)

summary(times)
```

The summary shows that 

 * 25% of the values are less than 10 microseconds whatever the folding factor
 
 * 50% of the values are still very small (less than 300 microseconds). 

 * The impact of folding seems to be visible from more than 150 microseconds (doubling median from 16 to 32)
 
 * For the first quartile and maximum values, we have something close to the expected slowdown.
 
```{r}
maximums<-c(max(time_regular$COMP.4b.avg),
            max(time_2$COMP.4b.avg),
            max(time_4$COMP.4b.avg),               
            max(time_8$COMP.4b.avg), 
            max(time_16$COMP.4b.avg), 
            max(time_32$COMP.4b.avg))
maximums /maximums[1]
```

Merge times and ratios in a single dataframe, and then keep only the 50 most time-consuming events in the trace. 

```{r}
time_and_ratio <- function (df){
  df2 = data.frame(df$COMP.4b.avg, df$COMP.4b.avg/time_regular$COMP.4b.avg)
  names(df2) = c("Time", "Ratio")
  return (df2)
}

tr2 <- time_and_ratio(time_2);
tr4 <- time_and_ratio(time_4);
tr8 <- time_and_ratio(time_8);
tr16 <- time_and_ratio(time_16);
tr32 <- time_and_ratio(time_32);

keeping_top<- function(threshold){
  t = floor(nrow(tr2)*threshold/100)
  df = data.frame(head(tr2[order(tr2$Time, decreasing=TRUE),],t)$Ratio,
                head(tr4[order(tr4$Time, decreasing=TRUE),],t)$Ratio,
                head(tr8[order(tr8$Time, decreasing=TRUE),],t)$Ratio,
                head(tr16[order(tr16$Time, decreasing=TRUE),],t)$Ratio,
                head(tr32[order(tr32$Time, decreasing=TRUE),],t)$Ratio)
  names(df)<- c(2,4,8,16,32)
  df <- melt(df)
  df$Events <- threshold
  return(df)
}
df100 <-keeping_top(100)
df50 <-keeping_top(50)
df25 <-keeping_top(25)
df10 <-keeping_top(10)
df5 <-keeping_top(5)

df = rbind (df100,df50,df25,df10,df5)
df$Events <- factor(df$Events, levels = sort(unique(df$Events),decreasing = TRUE))
```

We see that the 1st, Median, and Mean evolve linearly with the folding factor to some extent. However, small values (Min and median for folding factors 2 and 4) are less impacted. 

To conclude, delta times stored in timed traces are impacted by the floding of the execution in opposition to instructions stored in time-independent traces. Morevover, the increase of the delta times is related to the folding factor only for large values, with a definition of "large" that is hard to define and not as clear as what we saw for the acquisition times. 

```{r}
ggplot(df, aes(variable, value, fill=Events))  + xlab("Folding Factor") + ylab("(Folded/Regular) Time Ratio") + geom_boxplot(outlier.shape = NA)+ scale_y_continuous(breaks=c(2^c(1:5)), limits=c(2,35)) + scale_fill_grey(breaks=unique(df$Events), labels=c("All", "Top 50%", "Top 25%", "Top 10%", "Top 5%")) +theme_bw() 
```


